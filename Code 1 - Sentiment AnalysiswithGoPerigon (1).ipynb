{"cells":[{"cell_type":"code","source":["#Improt necessary libraries\n","import requests\n","import pandas as pd\n","import nltk\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","from datetime import datetime, timedelta\n","import time\n","from google.colab import files\n","import re\n","\n","# Connect to Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2duvrM3WaKE","executionInfo":{"status":"ok","timestamp":1724764344804,"user_tz":-60,"elapsed":26945,"user":{"displayName":"Hinosha Niyas","userId":"04525886576580999788"}},"outputId":"f4f709f3-1158-418b-cde5-969329df3cb2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Read a CSV file from Google Drive\n","df = pd.read_csv('/content/drive/MyDrive/Masters/Dissertation/API_details.txt')\n","\n","# Read a text file from Google Drive which contains API key and end point\n","with open('/content/drive/MyDrive/Masters/Dissertation/API_details.txt', 'r') as f:\n","  text = f.read()\n","\n","first_line = text.split('\\n')[0]\n","second_line = text.split('\\n')[1]\n"],"metadata":{"id":"M81gALT8Wf4s","executionInfo":{"status":"ok","timestamp":1724764386523,"user_tz":-60,"elapsed":866,"user":{"displayName":"Hinosha Niyas","userId":"04525886576580999788"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Download VADER lexicon\n","nltk.download('vader_lexicon')\n","\n","# Initialize the Sentiment Intensity Analyzer\n","sia = SentimentIntensityAnalyzer()\n","\n","# API configuration. These token taken from perigon\n","api_token = first_line\n","base_url = second_line\n","\n","# Fetch news data for a specific date range and query\n","def fetch_news(start_date, end_date, query):\n","    headers = {\n","        'Authorization': f'Bearer {api_token}'\n","    }\n","    # param dictionary to define query parameters\n","    params = {\n","        'q': query,\n","        'from': start_date,\n","        'to': end_date,\n","        'language': 'en',\n","        'sort': 'date',\n","        'size': 100\n","    }\n","    response = requests.get(base_url, headers=headers, params=params)\n","    if response.status_code == 200:\n","        return response.json().get('articles', [])\n","    elif response.status_code == 400:\n","        print(f\"Bad Request: Check parameters for {start_date} to {end_date}. Response: {response.json()}\")\n","        return []\n","    elif response.status_code == 402:\n","        print(\"Payment Required: You have exceeded your free tier usage limits or need to upgrade your plan.\")\n","        return []\n","    else:\n","        print(f\"Failed to fetch news for {start_date} to {end_date}: {response.status_code}\")\n","        return []\n","\n","# Function to clean text\n","def clean_text(text):\n","    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n","\n","# Function to analyze sentiment and save results to CSV files\n","def analyze_and_save(start_date, end_date, query, file_prefix):\n","    # Create DataFrames to hold results\n","    sentiment_columns = [\"Date\", \"News\", \"Positive\", \"Neutral\", \"Negative\", \"Final Sentiment\"]\n","    articles_df = pd.DataFrame(columns=[\"Date\", \"Title\", \"Content\", \"Sentiment\"])\n","    sentiment_df = pd.DataFrame(columns=sentiment_columns)\n","\n","    current_date = start_date\n","\n","    while current_date <= end_date:\n","        next_date = current_date + timedelta(days=1)\n","        articles = fetch_news(current_date.strftime('%Y-%m-%d'), next_date.strftime('%Y-%m-%d'), query)\n","        for article in articles:\n","            content = article['content'] if article['content'] else article.get('summary', '')\n","            if content and 'pubDate' in article:\n","                content_clean = clean_text(content)\n","                scores = sia.polarity_scores(content_clean)\n","                final_sentiment = scores['pos'] - scores['neg']\n","                article_row = pd.DataFrame([{\n","                    \"Date\": article['pubDate'][:10],\n","                    \"Title\": article['title'],\n","                    \"Content\": content_clean,\n","                    \"Sentiment\": final_sentiment\n","                }])\n","                sentiment_row = pd.DataFrame([{\n","                    \"Date\": article['pubDate'][:10],\n","                    \"News\": content_clean,\n","                    \"Positive\": scores['pos'],\n","                    \"Neutral\": scores['neu'],\n","                    \"Negative\": scores['neg'],\n","                    \"Final Sentiment\": final_sentiment\n","                }])\n","                articles_df = pd.concat([articles_df, article_row], ignore_index=True)\n","                sentiment_df = pd.concat([sentiment_df, sentiment_row], ignore_index=True)\n","\n","        # Save interim results every day\n","        articles_df.to_csv(f\"{file_prefix}_news_articles_all.csv\", index=False, encoding='utf-8-sig')\n","        sentiment_df.to_csv(f\"{file_prefix}_sentiment_analysis_all.csv\", index=False, encoding='utf-8-sig')\n","\n","        current_date = next_date\n","        time.sleep(1)  # Sleep to avoid hitting the rate limit\n","\n","    print(f\"News articles saved to {file_prefix}_news_articles_all.csv\")\n","    print(f\"Sentiment analysis saved to {file_prefix}_sentiment_analysis_all.csv\")\n","\n","    # Download the files\n","    files.download(f'{file_prefix}_news_articles_all.csv')\n","    files.download(f'{file_prefix}_sentiment_analysis_all.csv')\n","\n","    return articles_df, sentiment_df\n","\n","user_dates = input(\"Please enter the number of days you need to look download: \")\n","\n","while True:\n","    if user_dates.isnumeric():\n","        user_dates = int(user_dates)\n","\n","        # Set up the date range\n","        start_date = datetime.now() - timedelta(days=user_dates)\n","        end_date = datetime.now()\n","\n","        # Analyze and save news for S&P 500\n","        articles_df, sentiment_df = analyze_and_save(start_date, end_date, 'S&P 500', 'spx500')\n","\n","        # Display dataframes\n","        print(articles_df.head())\n","        print(sentiment_df.head())\n","        break  # Exit the loop after processing\n","    else:\n","        user_dates = input(\"Invalid data. Please enter the number of days you need to look download: \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":627},"id":"tr1iX2B5Myyu","executionInfo":{"status":"ok","timestamp":1724764439703,"user_tz":-60,"elapsed":43898,"user":{"displayName":"Hinosha Niyas","userId":"04525886576580999788"}},"outputId":"002de695-3a11-4148-8915-d5a125fb4e0a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"name":"stdout","output_type":"stream","text":["Please enter the number of days you need to look download: 14\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-7d417b2bf4ea>:74: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  articles_df = pd.concat([articles_df, article_row], ignore_index=True)\n","<ipython-input-3-7d417b2bf4ea>:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  sentiment_df = pd.concat([sentiment_df, sentiment_row], ignore_index=True)\n"]},{"output_type":"stream","name":"stdout","text":["News articles saved to spx500_news_articles_all.csv\n","Sentiment analysis saved to spx500_sentiment_analysis_all.csv\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9fb40127-f815-4ed0-a019-be16a7b02c09\", \"spx500_news_articles_all.csv\", 443961)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_dbb1f638-a3b2-47ac-bb0c-fac85036d2e9\", \"spx500_sentiment_analysis_all.csv\", 363528)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["         Date                                       Title  \\\n","0  2024-08-13                     S&P 500 Momentum Report   \n","1  2024-08-13                  S&P 500 Analyst Moves: KEY   \n","2  2024-08-13             CRITICAL Week Ahead for S&P 500   \n","3  2024-08-13      S&P 500 Gains 1.7% in Everything Rally   \n","4  2024-08-14  The Highest Yielding Stocks In the S&P 500   \n","\n","                                             Content  Sentiment  \n","0  All eyes on upcoming US inflation data this we...     -0.036  \n","1  The latest tally of analyst opinions from the ...      0.000  \n","2  In this video from StockCharts TV, Julius asse...      0.068  \n","3  The stock market rallied across the board on T...      0.125  \n","4  The Highest Yielding Stocks In the S&P 500\\n\\n...      0.000  \n","         Date                                               News  Positive  \\\n","0  2024-08-13  All eyes on upcoming US inflation data this we...     0.000   \n","1  2024-08-13  The latest tally of analyst opinions from the ...     0.000   \n","2  2024-08-13  In this video from StockCharts TV, Julius asse...     0.068   \n","3  2024-08-13  The stock market rallied across the board on T...     0.125   \n","4  2024-08-14  The Highest Yielding Stocks In the S&P 500\\n\\n...     0.000   \n","\n","   Neutral  Negative  Final Sentiment  \n","0    0.964     0.036           -0.036  \n","1    1.000     0.000            0.000  \n","2    0.932     0.000            0.068  \n","3    0.875     0.000            0.125  \n","4    1.000     0.000            0.000  \n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1FsA_io-Rch5pE9L6H7tIJieN7gsGXQki","timestamp":1719395609203}],"authorship_tag":"ABX9TyM9Y1OYzbgc5DH7sMS36DZS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}